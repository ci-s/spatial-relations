{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct MultilayerPerceptron\n",
    "    layers\n",
    "    MultilayerPerceptron(layers...) = new(layers)\n",
    "end\n",
    "(m::MultilayerPerceptron)(x) = (for l in m.layers; x = l(x); end; x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Layer0; w; b; end\n",
    "Layer0(ir::Int, ic::Int, o::Int) = Layer0(param(o,ir),param0(o, ic))\n",
    "(l::Layer0)(x) = (l.w * x .+ l.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct EmbedModel\n",
    "    w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbedModel"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function EmbedModel()\n",
    "    dim1 = 30\n",
    "    dim2 = EMBEDDING_SIZE\n",
    "    dim3 = 32\n",
    "    w = reshape(KnetArray(Knet.xavier(dim1*dim2*dim3)), (1,dim1,dim2,dim3))\n",
    "    return EmbedModel(w)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (e::EmbedModel)(x)\n",
    "    output = conv4(e.w, x, dilation=2)\n",
    "    return output\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct CaptionEncoder\n",
    "    embed_model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CaptionEncoder"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function CaptionEncoder()\n",
    "   embed_model = EmbedModel()\n",
    "   return CaptionEncoder(embed_model)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (c::CaptionEncoder)(captions, vocabid, vocab)\n",
    "    vocabid, vocab, caption_embeds = arrange(captions, vocabid, vocab)\n",
    "    input = createconvinput(caption_embeds)\n",
    "    input = reshape(input, (1, MAX_LENGTH, EMBEDDING_SIZE, BATCH_SIZE*NUM_CAPTIONS_PER_SCENE))\n",
    "    di_hat = c.embed_model(input)\n",
    "    captions_hat = convert(KnetArray{Float32}, reshape(reshape(di_hat, (2, 32, BATCH_SIZE*NUM_CAPTIONS_PER_SCENE)), (EMBEDDING_SIZE, BATCH_SIZE*NUM_CAPTIONS_PER_SCENE)))\n",
    "    return captions_hat, vocabid, vocab\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct AngleEncoder\n",
    "    mlp_model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AngleEncoder"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function AngleEncoder()\n",
    "    dim1 = 2 # cos and sin\n",
    "    dim2 = BATCH_SIZE*NUM_CAPTIONS_PER_SCENE\n",
    "    dim3 = 32 # from paper\n",
    "    mlp1=MultilayerPerceptron(Layer0(dim1, dim2, dim3)) # MLP1 dimensionality 32\n",
    "    return AngleEncoder(mlp1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (a::AngleEncoder)(cameras)\n",
    "    tuples = build_angles(cameras)\n",
    "    cameras_hat = a.mlp_model(tuples)\n",
    "    return cameras_hat\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct ImageConvModel\n",
    "    w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageConvModel"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ImageConvModel()\n",
    "    dim1 = 17\n",
    "    dim2 = 17\n",
    "    dim3 = 3 # RGB\n",
    "    w = reshape(KnetArray{Float32}(Knet.xavier(dim1*dim2*dim3)), (dim1,dim2,dim3,1))\n",
    "    return ImageConvModel(w)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (i::ImageConvModel)(x)\n",
    "    output = conv4(i.w, x)\n",
    "    return output\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct ImageEncoder\n",
    "    image_conv_model\n",
    "    sampling_model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageEncoder"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ImageEncoder()\n",
    "    image_conv_model = ImageConvModel()\n",
    "    sampling_model = MultilayerPerceptron(Layer0(256,450,128), Layer0(128, 450, 18))\n",
    "    return ImageEncoder(image_conv_model, sampling_model)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (i::ImageEncoder)(images)\n",
    "    imgencoderin = createimgencinput(images)\n",
    "    imgencoderin2 = pool(imgencoderin, window=4, stride=4)\n",
    "    himg = i.image_conv_model(imgencoderin2)\n",
    "    himg = himg[:,:,1,:]\n",
    "    himg = reshape(himg, (256,450))\n",
    "    z = reshape(i.sampling_model(himg), (162, 50))\n",
    "    return z\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct RepresentationModel\n",
    "    caption_encoder\n",
    "    angle_encoder\n",
    "    image_encoder\n",
    "    mlp_model #mlp2 that takes concatenated di_hat and ci_hat, output = hi_hat\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepresentationModel"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function RepresentationModel()\n",
    "    caption_encoder = CaptionEncoder()\n",
    "    angle_encoder = AngleEncoder()\n",
    "    image_encoder = ImageEncoder()\n",
    "    mlp_model = MultilayerPerceptron(Layer0(96, 500, 128), Layer0(128, 500, 196), Layer0(196, 500, 256)) # MLP2 dimensionality 256\n",
    "   return RepresentationModel(caption_encoder, angle_encoder, image_encoder, mlp_model) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (re::RepresentationModel)(images, captions, cameras, vocabid, vocab)\n",
    "    captions_hat, vocabid, vocab = re.caption_encoder(captions, vocabid, vocab)\n",
    "    cameras_hat = re.angle_encoder(cameras)\n",
    "    \n",
    "    unseen_ang = []\n",
    "    for i in 1:size(cameras_hat, 2)\n",
    "        if mod(i,10) == 0\n",
    "           push!(unseen_ang, cameras_hat[:,i]) \n",
    "        end\n",
    "    end\n",
    "    unseen_ang = hcat(unseen_ang...)\n",
    "    \n",
    "    h = re.mlp_model(cat(captions_hat, cameras_hat, dims=1))\n",
    "    r = aggregate(h)\n",
    "    z = re.image_encoder(images)\n",
    "    \n",
    "    return r, z, unseen_ang, vocabid, vocab\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(K32(256,50)[-0.007723382⋯], K32(162,50)[-0.010074977⋯], K32(32,50)[-0.07459014⋯], Dict(\"pink\" => 44,\"cone\" => 15,\"right\" => 19,\"capsule\" => 6,\"teal\" => 47,\"of\" => 14,\"purple\" => 8,\"cylinder\" => 21,\"right.\" => 26,\"to\" => 11…), K64(64,47)[0.0⋯])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representationModel = RepresentationModel()\n",
    "r, z, unseen_ang, vocabid, vocab = representationModel(aimages, acaptions, acameras, vocabid, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct GenerationModel\n",
    "    w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationModel"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function GenerationModel()\n",
    "    dim1 = 32\n",
    "    dim2 = 32\n",
    "    dim3 = 3 # RGB\n",
    "    dim4 = 450\n",
    "    w = reshape(KnetArray{Float32}(Knet.xavier(dim3*dim1*dim2*dim4)), (dim1,dim2,dim3,dim4))\n",
    "    return GenerationModel(w)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (g::GenerationModel)(x)\n",
    "    final_output = deconv4(g.w, x)\n",
    "    return final_output\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Network\n",
    "    representationModel\n",
    "    generationModel\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Network()\n",
    "    representationModel = RepresentationModel()\n",
    "    generationModel = GenerationModel()\n",
    "    return Network(representationModel, generationModel)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (n::Network)(images, captions, cameras, vocabid, vocab)\n",
    "    r, z, unseen_ang, vocabid, vocab = n.representationModel(images, captions, cameras, vocabid, vocab)\n",
    "    gen_input = reshape(vcat(z, vcat(r, unseen_ang)),(1,1,450,50)) # decoder input\n",
    "    output = n.generationModel(gen_input)\n",
    "    return output, vocabid, vocab\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
