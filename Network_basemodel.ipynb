{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct MultilayerPerceptron\n",
    "    layers\n",
    "    MultilayerPerceptron(layers...) = new(layers)\n",
    "end\n",
    "(m::MultilayerPerceptron)(x) = (for l in m.layers; x = l(x); end; x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Layer0; w; b; end\n",
    "Layer0(ir::Int, ic::Int, o::Int) = Layer0(param(o,ir),param0(o, ic))\n",
    "(l::Layer0)(x) = (l.w * x .+ l.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "mutable struct EmbedModel\n",
    "    w\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "function EmbedModel()\n",
    "    dim1 = 30\n",
    "    dim2 = 64 #EMBEDDING_SIZE\n",
    "    dim3 = 32\n",
    "    w = Param(reshape(KnetArray{Float32}(Knet.xavier(dim1*dim2*dim3)), (1,dim1,dim2,dim3)))\n",
    "    return EmbedModel(w)\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "function (e::EmbedModel)(x)\n",
    "    output = conv4(value(e.w), x, dilation=2)\n",
    "    return output\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvModel"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct ConvModel; w; b; f; end\n",
    "(c::ConvModel)(x) = c.f.(conv4(c.w, x, dilation=2) .+ c.b)\n",
    "ConvModel(w1,w2,cx,cy,f=relu) = ConvModel(param(w1,w2,cx,cy), param0(1,2,cy,1), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct CaptionEncoder\n",
    "    conv_model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CaptionEncoder"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function CaptionEncoder()\n",
    "    dim1 = 30\n",
    "    dim2 = 64 #EMBEDDING_SIZE\n",
    "    dim3 = 32    \n",
    "   conv_model = ConvModel(1,dim1,dim2,dim3)\n",
    "   return CaptionEncoder(conv_model)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (c::CaptionEncoder)(captions, vocabid, vocab)\n",
    "    vocabid, vocab, caption_embeds = arrange(captions, vocabid, vocab)\n",
    "    input = createconvinput(caption_embeds)\n",
    "    input = reshape(input, (1, MAX_LENGTH, EMBEDDING_SIZE, BATCH_SIZE*NUM_CAPTIONS_PER_SCENE))\n",
    "    di_hat = c.conv_model(input)\n",
    "    captions_hat = reshape(reshape(di_hat, (2, 32, BATCH_SIZE*NUM_CAPTIONS_PER_SCENE)), (EMBEDDING_SIZE, BATCH_SIZE*NUM_CAPTIONS_PER_SCENE))\n",
    "    return captions_hat, vocabid, vocab\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct AngleEncoder\n",
    "    mlp_model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AngleEncoder"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function AngleEncoder()\n",
    "    dim1 = 2 # cos and sin\n",
    "    dim2 = BATCH_SIZE*NUM_CAPTIONS_PER_SCENE\n",
    "    dim3 = 32 # from paper\n",
    "    mlp1=MultilayerPerceptron(Layer0(dim1, dim2, dim3)) # MLP1 dimensionality 32\n",
    "    return AngleEncoder(mlp1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (a::AngleEncoder)(cameras)\n",
    "    tuples = build_angles(cameras)\n",
    "    cameras_hat = a.mlp_model(tuples)\n",
    "    return cameras_hat\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "mutable struct ImageConvModel\n",
    "    w\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "function ImageConvModel()\n",
    "    dim1 = 17\n",
    "    dim2 = 17\n",
    "    dim3 = 3 # RGB\n",
    "    w = reshape(KnetArray{Float32}(Knet.xavier(dim1*dim2*dim3)), (dim1,dim2,dim3,1))\n",
    "    return ImageConvModel(w)\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "function (i::ImageConvModel)(x)\n",
    "    output = conv4(i.w, x)\n",
    "    return output\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageConvModel"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct ImageConvModel; w; b; f; end\n",
    "(i::ImageConvModel)(x) = i.f.(conv4(i.w, x) .+ i.b)\n",
    "ImageConvModel(w1,w2,cx,cy,f=relu) = ImageConvModel(param(w1,w2,cx,cy), param0(16,16,cy,1), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct ImageEncoder\n",
    "    image_conv_model\n",
    "    sampling_model\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageEncoder"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ImageEncoder()\n",
    "    image_conv_model = ImageConvModel(17, 17, 3, 1)\n",
    "    sampling_model = MultilayerPerceptron(Layer0(256,450,128), Layer0(128, 450, 18))\n",
    "    return ImageEncoder(image_conv_model, sampling_model)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (i::ImageEncoder)(images)\n",
    "    imgencoderin = createimgencinput(images)\n",
    "    imgencoderin2 = pool(imgencoderin, window=4, stride=4)\n",
    "    himg = i.image_conv_model(imgencoderin2)\n",
    "    himg = himg[:,:,1,:]\n",
    "    himg = reshape(himg, (256,450))\n",
    "    z = reshape(i.sampling_model(himg), (162, 50))\n",
    "    return z\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct RepresentationModel\n",
    "    caption_encoder\n",
    "    angle_encoder\n",
    "    image_encoder\n",
    "    mlp_model #mlp2 that takes concatenated di_hat and ci_hat, output = hi_hat\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepresentationModel"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function RepresentationModel()\n",
    "    caption_encoder = CaptionEncoder()\n",
    "    angle_encoder = AngleEncoder()\n",
    "    image_encoder = ImageEncoder()\n",
    "    mlp_model = MultilayerPerceptron(Layer0(96, 500, 128), Layer0(128, 500, 196), Layer0(196, 500, 256)) # MLP2 dimensionality 256\n",
    "   return RepresentationModel(caption_encoder, angle_encoder, image_encoder, mlp_model) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (re::RepresentationModel)(images, captions, cameras, vocabid, vocab)\n",
    "    captions_hat, vocabid, vocab = re.caption_encoder(captions, vocabid, vocab)\n",
    "    cameras_hat = re.angle_encoder(cameras)\n",
    "    \n",
    "    # move!\n",
    "    unseen_ang = []\n",
    "    for i in 1:size(cameras_hat, 2)\n",
    "        if mod(i,10) == 0\n",
    "           push!(unseen_ang, cameras_hat[:,i]) \n",
    "        end\n",
    "    end\n",
    "    unseen_ang = hcat(unseen_ang...)\n",
    "    unseen_img = pool(permutedims(images[:,10,:,:,:], (2,3,4,1)), window=4, stride=4) # shall the batchsize be in the end\n",
    "    \n",
    "    h = re.mlp_model(cat(captions_hat, cameras_hat, dims=1))\n",
    "    r = aggregate(h)\n",
    "    z = re.image_encoder(images)\n",
    "    \n",
    "    return r, z, unseen_ang, unseen_img, vocabid, vocab\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationModel"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct GenerationModel; w; b; f; end\n",
    "(ge::GenerationModel)(x) = relu.(deconv4(ge.w, x) .+ ge.b)\n",
    "GenerationModel() = GenerationModel(param(32,32,3,450), param0(32,32,3,1), relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "function GenerationModel()\n",
    "    dim1 = 32\n",
    "    dim2 = 32\n",
    "    dim3 = 3 # RGB\n",
    "    dim4 = 450\n",
    "    w = reshape(KnetArray{Float32}(Knet.xavier(dim3*dim1*dim2*dim4)), (dim1,dim2,dim3,dim4))\n",
    "    return GenerationModel(w)\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=\n",
    "function (g::GenerationModel)(x)\n",
    "    final_output = deconv4(g.w, x)\n",
    "    return final_output\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Network\n",
    "    representationModel\n",
    "    generationModel\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Network()\n",
    "    representationModel = RepresentationModel()\n",
    "    generationModel = GenerationModel()\n",
    "    return Network(representationModel, generationModel)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "function (n::Network)(images, captions, cameras, vocabid, vocab)\n",
    "    r, z, unseen_ang, unseen_img, vocabid, vocab = n.representationModel(images, captions, cameras, vocabid, vocab)\n",
    "    gen_input = reshape(vcat(z, vcat(r, unseen_ang)),(1,1,450,50)) # decoder input\n",
    "    output = n.generationModel(gen_input)\n",
    "    return output #, vocabid, vocab\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32×2 KnetArray{Float32,2}:\n",
       "  0.0122153    0.00147552\n",
       "  0.181434    -0.104982  \n",
       " -0.00618836   0.0924101 \n",
       "  0.14375     -0.192867  \n",
       " -0.158582     0.171397  \n",
       "  0.170024    -0.114838  \n",
       "  0.229864    -0.18594   \n",
       " -0.140441    -0.123064  \n",
       " -0.0501638   -0.157717  \n",
       "  0.138755     0.219494  \n",
       "  0.0531359   -0.105213  \n",
       " -0.083853    -0.155687  \n",
       "  0.071052    -0.0338888 \n",
       "  ⋮                      \n",
       "  0.0477721   -0.139004  \n",
       "  0.207031     0.190264  \n",
       " -0.0376994   -0.165688  \n",
       "  0.0328238    0.210589  \n",
       "  0.0606524   -0.0770972 \n",
       " -0.0142767   -0.0843005 \n",
       " -0.236633    -0.107708  \n",
       " -0.20422     -0.0378661 \n",
       "  0.219459     0.14916   \n",
       "  0.0987915   -0.14041   \n",
       " -0.172657     0.132751  \n",
       "  0.136296    -0.145437  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train!@DRAW correspondence\n",
    "function update_weights!(n::Network, x, y)\n",
    "    J = @diff bce(n(x), y)\n",
    "    for par in params(n)\n",
    "        g = grad(J, par)\n",
    "        update!(value(par), g; lr=0.1)\n",
    "    end\n",
    "    # return?\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
